{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e55c8fcd-71cd-470d-ada9-bbce0152ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0405 21:09:24.952613000 4753593856 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "E0405 21:09:26.987338000 4753593856 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "E0405 21:09:28.486340000 4753593856 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "E0405 21:09:31.298611000 4753593856 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "E0405 21:09:32.584272000 4753593856 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "E0405 21:09:34.148631000 4753593856 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip3 install --upgrade google-cloud-aiplatform\n",
    "!pip3 install --upgrade kfp\n",
    "!pip3 install --upgrade google-cloud-pipeline-components\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install pandas\n",
    "!pip3 install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f61dd-f7f2-4a2a-97dc-3c29d7360c82",
   "metadata": {},
   "source": [
    "### Good resources for custom components\n",
    "https://github.com/googleapis/python-aiplatform/tree/main/samples/model-builder\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples\n",
    "\n",
    "https://googleapis.dev/python/aiplatform/latest/aiplatform.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e3a35-d9e5-4171-8cf7-d3ecca9cc44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b48148fb-0cd6-4d57-b745-d57de9bb6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as vertex\n",
    "import kfp\n",
    "#from kfp import dsl\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output, OutputPath, component, ClassificationMetrics, Metrics)\n",
    "from google_cloud_pipeline_components import aiplatform as vertex_components\n",
    "from google_cloud_pipeline_components.types import artifact_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda4133-2220-41f8-ad6f-cb0243887ff1",
   "metadata": {},
   "source": [
    "https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.dsl.html\n",
    "\n",
    "https://pypi.org/project/google-cloud-aiplatform/\n",
    "\n",
    "https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4043be60-84f5-4aa5-92c3-80bbe2f58759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Creating gs://test-fast/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'test-fast' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n",
      "      1552  2022-03-24T21:14:19Z  gs://test-fast/aiplatform-2022-03-24-21:14:19.320-aiplatform_custom_trainer_script-0.1.tar.gz#1648156459408486  metageneration=1\n",
      "      1774  2022-03-27T08:32:44Z  gs://test-fast/aiplatform-2022-03-27-11:32:43.707-aiplatform_custom_trainer_script-0.1.tar.gz#1648369964419591  metageneration=1\n",
      "        60  2021-11-14T15:38:56Z  gs://test-fast/batch_test.csv#1636904336323978  metageneration=1\n",
      "        52  2021-11-14T16:14:44Z  gs://test-fast/batch_test1.csv#1636906484597636  metageneration=1\n",
      "                                 gs://test-fast/aiplatform-custom-training-2022-03-24-21:14:19.437/\n",
      "                                 gs://test-fast/aiplatform-custom-training-2022-03-27-11:32:44.390/\n",
      "                                 gs://test-fast/census/\n",
      "                                 gs://test-fast/data/\n",
      "                                 gs://test-fast/executor_files/\n",
      "                                 gs://test-fast/prediction-fast-test-12-2021_11_14T07_54_09_554Z/\n",
      "                                 gs://test-fast/prediction-fast-test-12-2021_11_14T08_41_08_653Z/\n",
      "                                 gs://test-fast/prediction-fast-test-12-2021_11_14T11_37_18_583Z/\n",
      "                                 gs://test-fast/prediction-fast-test-12-2022_02_21T00_25_18_548Z/\n",
      "TOTAL: 4 objects, 3438 bytes (3.36 KiB)\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"kubeflow-demos\"  # @param {type:\"string\"}\n",
    "PROJECT_NUMBER = \"141610882258\"\n",
    "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
    "BUCKET_NAME = \"test-fast\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "\n",
    "!gsutil mb -l $REGION $BUCKET_URI\n",
    "!gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "917434ed-2b9e-4be7-9f35-08e1e01e06fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34c6144-e2e9-450e-a93c-397aa5228572",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    # your Google Cloud Project ID or number\n",
    "    # environment default used is not set\n",
    "    project=PROJECT_ID,\n",
    "\n",
    "    # the Vertex AI region you will use\n",
    "    # defaults to us-central1\n",
    "    location=REGION,\n",
    "\n",
    "    # Google Cloud Storage bucket in same region as location\n",
    "    # used to stage artifacts\n",
    "    staging_bucket=BUCKET_URI,\n",
    "\n",
    "    # the name of the experiment to use to track\n",
    "    # logged metrics and parameters\n",
    "    experiment='my-experiment',\n",
    "\n",
    "    # description of the experiment above\n",
    "    experiment_description='my experiment description'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a7a6d4-7503-4308-97dc-65db97729a72",
   "metadata": {},
   "source": [
    "https://pypi.org/project/google-cloud-aiplatform/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6ba7cabc-ad5e-48d5-88c7-8dbd1f7d186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_FILE = (\n",
    "    \"gs://cloud-samples-data/vision/automl_classification/flowers/10_daisies.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d3479-d4ce-4484-baa6-d428d819f6ae",
   "metadata": {},
   "source": [
    "# AutoML training job\n",
    "AutoML can be used to automatically train a wide variety of image model types. AutoML automates the following:\n",
    "\n",
    "* Dataset preprocessing\n",
    "* Feature Engineering\n",
    "* Data feeding\n",
    "* Model Architecture selection\n",
    "* Hyperparameter tuning\n",
    "* Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4812c2cd-2423-4967-9e00-20150cb706f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/141610882258/locations/us-central1/datasets/3035228236754714624/operations/7348197355599953920\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/141610882258/locations/us-central1/datasets/3035228236754714624\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/141610882258/locations/us-central1/datasets/3035228236754714624')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/141610882258/locations/us-central1/datasets/3035228236754714624\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/141610882258/locations/us-central1/datasets/3035228236754714624/operations/8153215788992430080\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/141610882258/locations/us-central1/pipelineJobs/train-opti20220404234854-20220404234858 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset data imported. Resource name: projects/141610882258/locations/us-central1/datasets/3035228236754714624\n",
      "projects/141610882258/locations/us-central1/datasets/3035228236754714624\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/141610882258/locations/us-central1/pipelineJobs/train-opti20220404234854-20220404234858 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "dataset = aiplatform.ImageDataset.create(\n",
    "    display_name=\"flowers_\" + TIMESTAMP,\n",
    "    gcs_source=[IMPORT_FILE],\n",
    "    import_schema_uri=aiplatform.schema.dataset.ioformat.image.single_label_classification,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "260669a6-50b1-4268-93b3-4de172248824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<google.cloud.aiplatform.datasets.image_dataset.ImageDataset object at 0x7fb12a389a00> \n",
       " resource name: projects/141610882258/locations/us-central1/datasets/5695729716623835136,\n",
       " <google.cloud.aiplatform.datasets.image_dataset.ImageDataset object at 0x7fb12a3f80d0> \n",
       " resource name: projects/141610882258/locations/us-central1/datasets/1359326225419468800,\n",
       " <google.cloud.aiplatform.datasets.image_dataset.ImageDataset object at 0x7fb12a476fd0> \n",
       " resource name: projects/141610882258/locations/us-central1/datasets/2808038348130615296,\n",
       " <google.cloud.aiplatform.datasets.image_dataset.ImageDataset object at 0x7fb12a47acd0> \n",
       " resource name: projects/141610882258/locations/us-central1/datasets/8031123200345636864,\n",
       " <google.cloud.aiplatform.datasets.image_dataset.ImageDataset object at 0x7fb12a3607f0> \n",
       " resource name: projects/141610882258/locations/us-central1/datasets/8225138624136478720,\n",
       " <google.cloud.aiplatform.datasets.image_dataset.ImageDataset object at 0x7fb12a47bb80> \n",
       " resource name: projects/141610882258/locations/us-central1/datasets/58581979527905280]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.ImageDataset.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "591b915d-2a76-4d6d-b61b-bcbabdcab077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/141610882258/locations/us-central1/datasets/5695729716623835136\n",
      "projects/141610882258/locations/us-central1/datasets/5695729716623835136\n"
     ]
    }
   ],
   "source": [
    "DATASET_ID = '5695729716623835136'\n",
    "DATASET_NAME = 'flowers_20220404145045'\n",
    "res_id = f'projects/{PROJECT_NUMBER}/locations/us-central1/datasets/{DATASET_ID}'\n",
    "print(res_id)\n",
    "dataset = aiplatform.ImageDataset(res_id)\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e0b1e-a29d-4ae9-9b75-bc29b95742e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.aiplatform.training_jobs.AutoMLImageTrainingJob object at 0x7f81e0b58b50>\n",
      "INFO:google.cloud.aiplatform.training_jobs:View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/60785950585782272?project=141610882258\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLImageTrainingJob projects/141610882258/locations/us-central1/trainingPipelines/60785950585782272 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLImageTrainingJob projects/141610882258/locations/us-central1/trainingPipelines/60785950585782272 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLImageTrainingJob projects/141610882258/locations/us-central1/trainingPipelines/60785950585782272 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLImageTrainingJob projects/141610882258/locations/us-central1/trainingPipelines/60785950585782272 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLImageTrainingJob projects/141610882258/locations/us-central1/trainingPipelines/60785950585782272 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLImageTrainingJob projects/141610882258/locations/us-central1/trainingPipelines/60785950585782272 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLImageTrainingJob projects/141610882258/locations/us-central1/trainingPipelines/60785950585782272 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLImageTrainingJob projects/141610882258/locations/us-central1/trainingPipelines/60785950585782272 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLImageTrainingJob projects/141610882258/locations/us-central1/trainingPipelines/60785950585782272 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLImageTrainingJob projects/141610882258/locations/us-central1/trainingPipelines/60785950585782272 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLImageTrainingJob projects/141610882258/locations/us-central1/trainingPipelines/60785950585782272 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "job = aiplatform.AutoMLImageTrainingJob(\n",
    "    display_name=\"flowers_\" + TIMESTAMP,\n",
    "    prediction_type=\"classification\",\n",
    "    multi_label=False,\n",
    "    model_type=\"CLOUD_LOW_LATENCY_1\",\n",
    "    base_model=None,\n",
    ")\n",
    "\n",
    "print(job)\n",
    "\n",
    "model = job.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=\"flowers_\" + TIMESTAMP,\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    "    budget_milli_node_hours=1000,\n",
    "    disable_early_stopping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa18f5-00bc-47fd-99fb-12426be6164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = ''\n",
    "res_id = f'projects/{PROJECT_NUMBER}/locations/us-central1/datasets/{MODEL_ID}'\n",
    "print(res_id)\n",
    "model = aiplatform.Model(res_id)\n",
    "print(model.resource_name)\n",
    "#model = aiplatform.Model('/projects/my-project/locations/us-central1/models/{MODEL_ID}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd2a85-ad6a-47e7-81ef-d579c518d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a reference to the Model Service client\n",
    "client_options = {\"api_endpoint\": f\"{REGION}-aiplatform.googleapis.com\"}\n",
    "model_service_client = aip.gapic.ModelServiceClient(client_options=client_options)\n",
    "\n",
    "model_evaluations = model_service_client.list_model_evaluations(\n",
    "    parent=models[0].resource_name\n",
    ")\n",
    "model_evaluation = list(model_evaluations)[0]\n",
    "print(model_evaluation)\n",
    "\n",
    "endpoint = model.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469683f-deed-4619-a37c-54ddc3a859ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component()\n",
    "def create_dataset():\n",
    "    \n",
    "@component()\n",
    "def train():\n",
    "    \n",
    "@component()\n",
    "def evaluate():\n",
    "    \n",
    "@component()\n",
    "def deploy():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c03a607c-9a78-4d23-b91a-3bcebd8e24f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0405 22:43:24.512370000 4753593856 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Updates are available for some Cloud SDK components.  To install them,\n",
      "please run:\n",
      "  $ gcloud components update\n",
      "\n",
      "gs://cloud-samples-data/vision/automl_classification/flowers/\n",
      "gs://cloud-samples-data/vision/automl_classification/flowers/10_daisies.csv\n",
      "gs://cloud-samples-data/vision/automl_classification/flowers/all_data_v2.csv\n",
      "gs://cloud-samples-data/vision/automl_classification/flowers/flowers-50.jsonl\n",
      "gs://cloud-samples-data/vision/automl_classification/flowers/flowers.jsonl\n",
      "gs://cloud-samples-data/vision/automl_classification/flowers/daisy/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://cloud-samples-data/vision/automl_classification/flowers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "1e0465f3-c900-4af1-b52c-08a2ef64f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6ed640c7-54d3-4a3c-90d9-beaa68cbb78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=[\"google-cloud-aiplatform\"])\n",
    "def create_image_dataset() -> str:\n",
    "    from datetime import datetime\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    import google.cloud.aiplatform as aiplatform\n",
    "\n",
    "    aiplatform.init(\n",
    "                    project='kubeflow-demos',\n",
    "                    location='us-central1',\n",
    "                    staging_bucket='gs://test-fast/',\n",
    "                    experiment='my-experiment',\n",
    "                    experiment_description='my experiment description')\n",
    "    \n",
    "    IMPORT_FILE = (\"gs://cloud-samples-data/vision/automl_classification/flowers/flowers-50.jsonl\")\n",
    "    \n",
    "    dataset = aiplatform.ImageDataset.create(\n",
    "                                            display_name=\"flowers_\" + TIMESTAMP,\n",
    "                                            gcs_source=[IMPORT_FILE],\n",
    "                                            import_schema_uri=aiplatform.schema.dataset.ioformat.image.single_label_classification)\n",
    "\n",
    "    print(dataset.resource_name)\n",
    "    \n",
    "    return dataset.resource_name\n",
    "\n",
    "@component(packages_to_install=[\"google-cloud-aiplatform\"])\n",
    "def create_tabular_dataset() -> str:\n",
    "    from datetime import datetime\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    import google.cloud.aiplatform as aiplatform\n",
    "\n",
    "    aiplatform.init(\n",
    "                    project='kubeflow-demos',\n",
    "                    location='us-central1',\n",
    "                    staging_bucket='gs://test-fast/',\n",
    "                    experiment='my-experiment',\n",
    "                    experiment_description='my experiment description')\n",
    "    \n",
    "    bq_source = f'bq://kubeflow-demos.flowers.iris'\n",
    "\n",
    "    dataset = aiplatform.TabularDataset.create(\n",
    "        display_name='iris', bq_source=bq_source,\n",
    "    )\n",
    "\n",
    "    dataset.wait()\n",
    "\n",
    "    print(f'\\tDataset: \"{dataset.display_name}\"')\n",
    "    print(f'\\tname: \"{dataset.resource_name}\"')\n",
    "    \n",
    "    return dataset.resource_name\n",
    "\n",
    "@component(packages_to_install=[\"google-cloud-aiplatform\"])\n",
    "def train_autoML_tabular(dataset_resource: str) -> str:\n",
    "    from datetime import datetime\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    import google.cloud.aiplatform as aiplatform\n",
    "\n",
    "    aiplatform.init(project='kubeflow-demos',\n",
    "                    location='us-central1',\n",
    "                    staging_bucket='gs://test-fast/',\n",
    "                    experiment='my-experiment',\n",
    "                    experiment_description='my experiment description')\n",
    "    \n",
    "    job = aiplatform.AutoMLTabularTrainingJob(\n",
    "                                        display_name=\"flowers_\" + TIMESTAMP,\n",
    "                                        optimization_prediction_type=\"classification\",\n",
    "                                        column_specs={\"petal_length\": \"auto\",\n",
    "                                                      \"petal_width\": \"auto\",\n",
    "                                                      \"sepal_length\": \"auto\",\n",
    "                                                      \"sepal_width\": \"auto\",\n",
    "                                                      \"species\": \"auto\"})\n",
    "\n",
    "    print(job)\n",
    "\n",
    "    flower_dataset = aiplatform.TabularDataset(dataset_resource)\n",
    "\n",
    "    model = job.run(\n",
    "                    dataset=flower_dataset,\n",
    "                    model_display_name=\"flowers_\" + TIMESTAMP,\n",
    "                    training_fraction_split=0.8,\n",
    "                    validation_fraction_split=0.1,\n",
    "                    test_fraction_split=0.1,\n",
    "                    budget_milli_node_hours=1000,\n",
    "                    disable_early_stopping=False,\n",
    "                    target_column=\"species\")\n",
    "    \n",
    "    model.wait()\n",
    "    \n",
    "    print(model.resource_name)\n",
    "    \n",
    "    return model.resource_name\n",
    "    \n",
    "@component(packages_to_install=[\"google-cloud-aiplatform\", \"google-cloud-storage\", \"catboost\", \"sklearn\"])\n",
    "def train_catboost():\n",
    "    print(\"train\")\n",
    "    import sklearn\n",
    "    from sklearn import datasets\n",
    "    iris = sklearn.datasets.load_iris()\n",
    "\n",
    "    import catboost\n",
    "    model = catboost.CatBoostClassifier(loss_function='MultiClass')\n",
    "\n",
    "    model.fit(iris.data, iris.target)\n",
    "    FILE_PATH = \"model\"\n",
    "    model.save_model(FILE_PATH)\n",
    "\n",
    "    from_file = catboost.CatBoostClassifier()\n",
    "\n",
    "    from google.cloud import storage\n",
    "\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    bucket_name = \"test-fast\"\n",
    "    # The path to your file to upload\n",
    "    source_file_name = FILE_PATH\n",
    "    # The ID of your GCS object\n",
    "    destination_blob_name = FILE_PATH\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        \"File {} uploaded to {}.\".format(\n",
    "            source_file_name, \"gs://\" + destination_blob_name\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "@component(packages_to_install=[\"google-cloud-aiplatform\", \"google-cloud-storage\", \"sklearn\"])\n",
    "def train_scikit():\n",
    "    print(\"train\")\n",
    "    import sklearn\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn import datasets\n",
    "    iris = sklearn.datasets.load_iris()\n",
    "\n",
    "    model = SVC()\n",
    "    model.fit(iris.data, iris.target)\n",
    "    \n",
    "    import pickle\n",
    "    # save the model to disk\n",
    "    FILE_PATH = 'finalized_model.sav'\n",
    "    pickle.dump(model, open(FILE_PATH, 'wb'))\n",
    "    \n",
    "    from google.cloud import storage\n",
    "\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    bucket_name = \"test-fast\"\n",
    "    # The path to your file to upload\n",
    "    source_file_name = FILE_PATH\n",
    "    # The ID of your GCS object\n",
    "    destination_blob_name = FILE_PATH\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        \"File {} uploaded to {}.\".format(\n",
    "            source_file_name, \"gs://\" + destination_blob_name\n",
    "        )\n",
    "    )\n",
    "@component(packages_to_install=[\"google-cloud-aiplatform\"])\n",
    "def evaluate(model_resource: str):\n",
    "    print(\"evaluate\")\n",
    "    \n",
    "    from datetime import datetime\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    import google.cloud.aiplatform as aiplatform\n",
    "\n",
    "    aiplatform.init(project='kubeflow-demos',\n",
    "                    location='us-central1',\n",
    "                    staging_bucket='gs://test-fast/',\n",
    "                    experiment='my-experiment',\n",
    "                    experiment_description='my experiment description')\n",
    "    \n",
    "    # Get model resource ID\n",
    "    models = aiplatform.Model(model_resource)\n",
    "\n",
    "    # Get a reference to the Model Service client\n",
    "    client_options = {\"api_endpoint\": \"us-central1-aiplatform.googleapis.com\"}\n",
    "    model_service_client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "\n",
    "    model_evaluations = model_service_client.list_model_evaluations(\n",
    "        parent=model_resource\n",
    "    )\n",
    "    model_evaluation = list(model_evaluations)[0]\n",
    "    \n",
    "    print(model_evaluation)\n",
    "    \n",
    "@component()\n",
    "def create_endpoint():\n",
    "    print(\"Endpoint\")\n",
    "    \n",
    "@component()\n",
    "def deploy():\n",
    "    print(\"deploy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fddb45-d074-4043-8ea1-6cf2f1eb4bee",
   "metadata": {},
   "source": [
    "https://www.kubeflow.org/docs/components/pipelines/sdk-v2/v2-component-io/\n",
    "\n",
    "https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.AutoMLTabularTrainingJob\n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/training/automl-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "72e6cfbe-591a-4b6c-87f6-3475de4dd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=\"train-opti\")\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    bucket: str = BUCKET_URI,\n",
    "    baseline_accuracy: float = 70.0\n",
    "):\n",
    "    create_tabular_dataset_task = create_tabular_dataset()\n",
    "    create_tabular_dataset_task.set_caching_options(True)\n",
    "    \n",
    "    train_autoML_task = train_autoML_tabular(create_tabular_dataset_task.output)\n",
    "    train_autoML_task.set_caching_options(True)\n",
    "    \n",
    "    train_catboost_task = train_catboost()\n",
    "    train_catboost_task.set_caching_options(True)\n",
    "    train_catboost_task.after(create_tabular_dataset_task)\n",
    "    \n",
    "    train_scikit_task = train_scikit()\n",
    "    train_scikit_task.set_caching_options(True)\n",
    "    train_scikit_task.after(create_tabular_dataset_task)\n",
    "    \n",
    "    evaluate_task = evaluate(train_autoML_task.output)\n",
    "    evaluate_task.set_caching_options(True)\n",
    "    evaluate_task.after(train_scikit_task)\n",
    "    evaluate_task.after(train_catboost_task)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "e14ac497-112e-44f4-943e-72a9b241bead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yarkoni/projects/workshop/venv/lib/python3.9/site-packages/kfp/v2/compiler/compiler.py:1278: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from kfp.v2 import compiler\n",
    "\n",
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"dag-\"+TIMESTAMP+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "88e76ae0-3171-4e4d-ae29-220a0f14dad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0406 18:29:47.302737000 4753593856 fork_posix.cc:76]                  Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/141610882258/locations/us-central1/pipelineJobs/train-opti-20220406182948\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/141610882258/locations/us-central1/pipelineJobs/train-opti-20220406182948')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/train-opti-20220406182948?project=141610882258\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/141610882258/locations/us-central1/pipelineJobs/train-opti-20220406182948\n"
     ]
    }
   ],
   "source": [
    "# Instantiate PipelineJob object\n",
    "pl = aiplatform.PipelineJob(\n",
    "    display_name=\"test-opti\",\n",
    "\n",
    "    # Whether or not to enable caching\n",
    "    # True = always cache pipeline step result\n",
    "    # False = never cache pipeline step result\n",
    "    # None = defer to cache option for each pipeline component in the pipeline definition\n",
    "    enable_caching=True,\n",
    "\n",
    "    # Local or GCS path to a compiled pipeline definition\n",
    "    template_path=\"dag-\"+TIMESTAMP+\".json\",\n",
    "\n",
    "    # Dictionary containing input parameters for your pipeline\n",
    "    parameter_values={},\n",
    "\n",
    "    # GCS path to act as the pipeline root\n",
    "    pipeline_root=BUCKET_URI,\n",
    ")\n",
    "\n",
    "# Execute pipeline in Vertex AI and monitor until completion\n",
    "pl.run(\n",
    "  # Email address of service account to use for the pipeline run\n",
    "  # You must have iam.serviceAccounts.actAs permission on the service account to use it\n",
    "  #service_account=service_account,\n",
    "\n",
    "  # Whether this function call should be synchronous (wait for pipeline run to finish before terminating)\n",
    "  # or asynchronous (return immediately)\n",
    "  sync=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bdbf98-57bc-4c17-9671-1d0832e571e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = aiplatform.PipelineJob.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82858c6c-ebd7-4cef-b29a-3ae2665be848",
   "metadata": {},
   "source": [
    "### Or simply use the premade components \n",
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/google_cloud_pipeline_components_automl_images.ipynb\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/automl_tabular_classification_beans.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f47b3-b11c-4855-9a20-638dbed91ff9",
   "metadata": {},
   "source": [
    "### Adding batch capabilities\n",
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/gapic/automl/showcase_automl_image_classification_batch.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba2736-1249-4e8f-8737-e95c9caf2f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
